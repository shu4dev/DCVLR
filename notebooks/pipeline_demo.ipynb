{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team-1 Data Synthesis Pipeline Demo\n",
    "\n",
    "This notebook demonstrates how to use the Team-1 Data Synthesis Pipeline to generate reasoning-focused Vision-Language datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import pipeline\n",
    "from team1_pipeline import DataSynthesisPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    'images_dir': '../data/sample_images',  # Update with your images directory\n",
    "    'output_dir': '../output/demo',\n",
    "    'config_path': '../configs/default_config.yaml',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = DataSynthesisPipeline(\n",
    "    config_path=config['config_path'],\n",
    "    images_dir=config['images_dir'],\n",
    "    output_dir=config['output_dir'],\n",
    "    device=config['device']\n",
    ")\n",
    "\n",
    "print(f\"Pipeline initialized on {config['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Individual Pipeline Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Filter Images\n",
    "print(\"Stage 1: Filtering images...\")\n",
    "filtered_images = pipeline.filter_stage(num_images=100)\n",
    "print(f\"Filtered to {len(filtered_images)} images\")\n",
    "\n",
    "# Display sample filtered images\n",
    "if filtered_images:\n",
    "    fig, axes = plt.subplots(1, min(3, len(filtered_images)), figsize=(12, 4))\n",
    "    for i, img_data in enumerate(filtered_images[:3]):\n",
    "        img = Image.open(img_data['path'])\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Image {i+1}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Bin Images\n",
    "print(\"Stage 2: Binning images...\")\n",
    "binned_images = pipeline.bin_stage(filtered_images, bins_ratio=(0.4, 0.4, 0.2))\n",
    "\n",
    "# Display bin distribution\n",
    "bin_counts = {k: len(v) for k, v in binned_images.items()}\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(bin_counts.keys(), bin_counts.values())\n",
    "plt.xlabel('Bin Category')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Image Distribution Across Bins')\n",
    "for i, (k, v) in enumerate(bin_counts.items()):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Bin A (Text/Arithmetic): {bin_counts['A']} images\")\n",
    "print(f\"Bin B (Object/Spatial): {bin_counts['B']} images\")\n",
    "print(f\"Bin C (Commonsense/Attribute): {bin_counts['C']} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: Generate Q/A Pairs\n",
    "print(\"Stage 3: Generating Q/A pairs...\")\n",
    "qa_dataset = pipeline.synthesis_stage(binned_images)\n",
    "print(f\"Generated {len(qa_dataset)} Q/A pairs\")\n",
    "\n",
    "# Display sample Q/A pairs\n",
    "if qa_dataset:\n",
    "    sample_qa = qa_dataset[0]\n",
    "    print(\"\\nSample Q/A pair:\")\n",
    "    print(f\"Image: {sample_qa['image']}\")\n",
    "    print(f\"Bin: {sample_qa['bin']}\")\n",
    "    print(f\"Question: {sample_qa.get('question', 'N/A')}\")\n",
    "    print(f\"Answer: {sample_qa.get('answer', 'N/A')}\")\n",
    "    print(f\"Reasoning: {sample_qa.get('reasoning', 'N/A')[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 4: Validate Dataset\n",
    "print(\"Stage 4: Validating dataset...\")\n",
    "validated_dataset = pipeline.validation_stage(qa_dataset)\n",
    "print(f\"Validated {len(validated_dataset)} Q/A pairs\")\n",
    "print(f\"Removed {len(qa_dataset) - len(validated_dataset)} invalid entries\")\n",
    "\n",
    "# Save validated dataset\n",
    "pipeline.save_dataset(validated_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Generated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze the dataset\n",
    "dataset_path = Path(config['output_dir']) / 'synthetic_qa_dataset.jsonl'\n",
    "\n",
    "data = []\n",
    "with open(dataset_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Total Q/A pairs: {len(df)}\")\n",
    "print(f\"\\nDistribution by bin:\")\n",
    "print(df['bin'].value_counts())\n",
    "\n",
    "# Question length distribution\n",
    "df['question_length'] = df['question'].str.split().str.len()\n",
    "df['answer_length'] = df['answer'].str.split().str.len()\n",
    "df['reasoning_length'] = df['reasoning'].str.split().str.len()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(df['question_length'], bins=20)\n",
    "axes[0].set_xlabel('Question Length (words)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Question Length Distribution')\n",
    "\n",
    "axes[1].hist(df['answer_length'], bins=20)\n",
    "axes[1].set_xlabel('Answer Length (words)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Answer Length Distribution')\n",
    "\n",
    "axes[2].hist(df['reasoning_length'], bins=20)\n",
    "axes[2].set_xlabel('Reasoning Length (words)')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Reasoning Length Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete pipeline end-to-end\n",
    "results = pipeline.run(\n",
    "    num_images=100,\n",
    "    bins_ratio=(0.4, 0.4, 0.2),\n",
    "    skip_benchmarking=True  # Skip benchmarking for demo\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nPipeline Results:\")\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample Q/A pairs from each bin\n",
    "for bin_type in ['A', 'B', 'C']:\n",
    "    bin_samples = df[df['bin'] == bin_type].head(2)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Bin {bin_type} Samples:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for idx, row in bin_samples.iterrows():\n",
    "        print(f\"\\nQuestion: {row['question']}\")\n",
    "        print(f\"Answer: {row['answer']}\")\n",
    "        print(f\"Reasoning: {row['reasoning'][:150]}...\")\n",
    "        print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
