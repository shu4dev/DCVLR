# Team-1 Data Synthesis Pipeline Configuration

# Image Filtering Settings
filtering:
  min_resolution: 256           # Minimum image width/height in pixels
  nsfw_threshold: 0.5           # NSFW detection threshold (0-1, lower is stricter)
  phash_threshold: 8            # Perceptual hash threshold for duplicate detection
  enable_watermark_check: true  # Enable watermark detection
  watermark_edge_ratio: 0.3     # Edge ratio threshold for watermark detection

# Image Binning Settings
binning:
  text_boxes_threshold: 2       # Min text boxes for Bin A (Text/Arithmetic)
  text_area_threshold: 0.2      # Min text area ratio for Bin A
  object_count_threshold: 5     # Min objects for Bin B (Object/Spatial)
  unique_objects_threshold: 3   # Min unique object types for Bin B
  clip_similarity_threshold: 0.25  # Min CLIP similarity for Bin C validation
  spatial_dispersion_threshold: 0.3  # Spatial dispersion threshold for complexity filtering

  # OCR Backend Selection
  use_paddle_ocr: false          # true = PaddleOCR (lightweight, ~200MB), false = DeepSeek-OCR (heavy, ~10GB)
                                # If use_paddle_ocr: false and DeepSeek fails (OOM), automatically falls back to PaddleOCR
                                # Recommended: Set to true for systems with limited VRAM (e.g., single RTX 2080 Ti)

  # DeepSeek-OCR model settings (only used if use_paddle_ocr: false)
  deepseek_model_size: 'tiny'   # Model size: 'tiny', 'small', 'base', 'large' (tiny uses least memory)

  # Multi-GPU settings
  enable_multi_gpu: true        # Auto-detect and distribute models across multiple GPUs
                                # With 1 GPU: all models on cuda:0
                                # With 2 GPUs: OCR on cuda:0, other models on cuda:1
                                # With 3+ GPUs: OCR on cuda:0, YOLO on cuda:1, CLIP/BLIP on cuda:2

  # Enhanced model options (merged from blip2.py and yolov11-filter.py)
  use_blip2: false              # Use BLIP-2 for higher quality captions (requires more GPU memory)

  # Object Detection Backend Selection
  object_detector: 'yolo'       # Options: 'yolo' or 'sam'
                                # yolo = Fast, provides class labels and object types
                                # sam = Slower, finds all objects/regions without classification

  # YOLO-specific settings (only used if object_detector: 'yolo')
  yolo_model: 'yolov8n'         # Options: 'yolov8n', 'yolov8s', 'yolov9s', 'yolov10s', 'yolov11s'
                                # n = nano (fastest, least accurate)
                                # s = small (balanced)

  # SAM-specific settings (only used if object_detector: 'sam')
  sam_model_type: 'vit_b'       # Options: 'vit_b' (375MB), 'vit_l' (1.2GB), 'vit_h' (2.4GB)
  sam_checkpoint: 'models/sam_vit_b_01ec64.pth'  # Path to SAM checkpoint file

# Q/A Synthesis Settings
synthesis:
  llm_model: "tiiuae/falcon-7b-instruct"  # LLM model for Q/A generation
  max_tokens: 512              # Max tokens for generation
  temperature: 0.7             # Sampling temperature
  top_p: 0.9                  # Nucleus sampling parameter
  do_sample: true             # Enable sampling
  num_templates_per_bin: 5    # Number of prompt templates per bin
  batch_size: 1               # Batch size for generation
  
  # Feature extraction settings
  ocr_lang: "en"              # OCR language
  use_angle_cls: true         # Enable angle classification in OCR
  yolo_model: "yolov8n.pt"    # YOLO model for object detection
  blip_model: "Salesforce/blip-image-captioning-base"  # BLIP model for captioning
  clip_model: "ViT-B-32"      # CLIP model for similarity

# Validation Settings
validation:
  min_question_length: 5       # Minimum words in question
  min_answer_length: 1         # Minimum words in answer
  min_reasoning_length: 10     # Minimum words in reasoning
  similarity_threshold: 0.9    # Text similarity threshold for duplicates
  enable_grounding_check: true # Enable source grounding validation
  enable_math_check: true      # Enable arithmetic validation
  math_tolerance: 1e-6        # Tolerance for math answer checking

# Hardware Settings
device:
  cuda_device: 0              # CUDA device index
  cpu_threads: 4              # Number of CPU threads
  mixed_precision: true       # Enable mixed precision
  
# Logging Settings
logging:
  level: "INFO"               # Logging level
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "pipeline.log"        # Log file name
  console: true               # Enable console logging

# Output Settings
output:
  save_intermediate: true     # Save intermediate results
  compression: "gzip"         # Compression for saved files
  formats:
    - jsonl                   # Output formats
    - csv
  
# Data Settings
data:
  image_extensions:           # Supported image extensions
    - .jpg
    - .jpeg
    - .png
    - .gif
    - .bmp
    - .webp
  
  max_images_per_batch: 100   # Max images to process per batch
  shuffle: true               # Shuffle images before processing
